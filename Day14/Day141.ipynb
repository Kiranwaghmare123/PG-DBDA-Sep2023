{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7adcaa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a79f340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640cd58",
   "metadata": {},
   "source": [
    "# 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16adb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "text=\"Hello there, how are you doing today? The weather is great today. The sky is blue. Python is awesome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d849173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there, how are you doing today?', 'The weather is great today.', 'The sky is blue.', 'Python is awesome']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4440c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'there', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', 'today', '.', 'The', 'sky', 'is', 'blue', '.', 'Python', 'is', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ea398",
   "metadata": {},
   "source": [
    "# 2. Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73e1e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ef2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove stopwords for a particular text\n",
    "from nltk.corpus import stopwords\n",
    "text = 'Vishal is a good boy. He is very good in coding.'\n",
    "text = word_tokenize(text)\n",
    "#ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e300c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vishal', 'good', 'boy', '.', 'He', 'good', 'coding', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_without_stopword = [word for word in text if word not in stopwords.words('english')]\n",
    "text_without_stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1482a68",
   "metadata": {},
   "source": [
    "# 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa8a8120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earn\n",
      "earn\n",
      "earn\n",
      "earn\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "example_word = ['earn',\"earning\",\"earned\",\"earns\"]\n",
    "\n",
    "for w in example_word:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cbbafb",
   "metadata": {},
   "source": [
    "# 4. Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afd9d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f753ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n",
      "formality\n",
      "change\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "example_word=['history','formality','changes']\n",
    "for w in example_word:\n",
    "    print(lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59991027",
   "metadata": {},
   "source": [
    "# 5. WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1379d88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'glad', 'felicitous', 'well-chosen', 'happy'}\n",
      "{'unhappy'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"happy\"):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())\n",
    "        if i.antonyms():\n",
    "            antonyms.append(i.antonyms()[0].name())\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f5ce1",
   "metadata": {},
   "source": [
    "# 6. Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e060c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32467685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '''\n",
    "An sincerity so extremity he additions. Her yet there truth merit. Mrs all projecting favourable now unpleasing. Son law garden chatty temper. Oh children provided to mr elegance marriage strongly. Off can admiration prosperous now devonshire diminution law.\n",
    "'''\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f1a3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('An', 'DT'), ('sincerity', 'NN'), ('so', 'RB'), ('extremity', 'NN'), ('he', 'PRP'), ('additions', 'VBZ'), ('.', '.'), ('Her', 'PRP$'), ('yet', 'RB'), ('there', 'EX'), ('truth', 'NN'), ('merit', 'NN'), ('.', '.'), ('Mrs', 'NNP'), ('all', 'DT'), ('projecting', 'VBG'), ('favourable', 'JJ'), ('now', 'RB'), ('unpleasing', 'VBG'), ('.', '.'), ('Son', 'NNP'), ('law', 'NN'), ('garden', 'NN'), ('chatty', 'JJ'), ('temper', 'NN'), ('.', '.'), ('Oh', 'UH'), ('children', 'NNS'), ('provided', 'VBD'), ('to', 'TO'), ('mr', 'VB'), ('elegance', 'NN'), ('marriage', 'NN'), ('strongly', 'RB'), ('.', '.'), ('Off', 'CC'), ('can', 'MD'), ('admiration', 'VB'), ('prosperous', 'JJ'), ('now', 'RB'), ('devonshire', 'VBP'), ('diminution', 'NN'), ('law', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580cd82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
